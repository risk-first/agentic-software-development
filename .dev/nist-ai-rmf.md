
# GOVERN — Organizational risk governance

## GOVERN 1 — Risk management policies and processes exist

* **1.1** Legal/regulatory AI requirements are understood and documented.
* **1.2** Trustworthy-AI characteristics are embedded into org policies and practices.
* **1.3** Required level of AI risk management is determined by risk tolerance.
* **1.4** Transparent risk-management procedures and controls are established.
* **1.5** Ongoing monitoring, review cadence, and responsibilities are defined.
* **1.6** AI system inventory exists and is resourced by risk priority.
* **1.7** Safe decommissioning/phase-out procedures are defined.

➡ **Theme:** institutionalize lifecycle AI risk governance.

---

## GOVERN 2 — Accountability structures

* **2.1** Roles, responsibilities, and reporting lines for AI risk are documented.
* **2.2** Personnel and partners receive AI risk-management training.
* **2.3** Executive leadership is accountable for AI risk decisions.

➡ **Theme:** governance must reach the C-suite.

---

## GOVERN 3 — Workforce diversity & inclusion in risk

* **3.1** Diverse, interdisciplinary teams inform AI risk decisions.
* **3.2** Human-AI oversight roles and responsibilities are clearly defined.

➡ **Theme:** socio-technical risk requires diverse perspectives.

---

## GOVERN 4 — Risk-aware organizational culture

* **4.1** Safety-first and critical-thinking culture is embedded.
* **4.2** AI risks and impacts are documented and communicated.
* **4.3** Testing, incident detection, and information-sharing practices exist.

➡ **Theme:** culture is a control surface.

---

## GOVERN 5 — External engagement

* **5.1** Feedback from affected stakeholders is collected and integrated.
* **5.2** Adjudicated external feedback informs system design and updates.

➡ **Theme:** legitimacy requires stakeholder input.

---

## GOVERN 6 — Third-party & supply-chain risk

* **6.1** Policies address third-party IP, data, and AI risks.
* **6.2** Contingency plans exist for third-party failures/incidents.

➡ **Theme:** AI supply chain = risk multiplier.

---

# MAP — Context and risk identification

## MAP 1 — Context establishment

* **1.1** Intended use, impacts, laws, users, and assumptions documented.
* **1.2** Diverse interdisciplinary context-setting participation ensured.
* **1.3** Organizational mission/goals for AI documented.
* **1.4** Business value/use context defined or re-evaluated.
* **1.5** Risk tolerance determined and documented.
* **1.6** Socio-technical system requirements defined.

➡ **Theme:** risk begins with context clarity.

---

## MAP 2 — AI system categorization

* **2.1** Tasks/methods (e.g., generative, classifier) defined.
* **2.2** Knowledge limits, human oversight, and usage constraints documented.
* **2.3** Scientific integrity and TEVV considerations documented.

➡ **Theme:** know what kind of AI you built.

---

## MAP 3 — Capabilities, benefits, and costs

* **3.1** Expected benefits documented.
* **3.2** Expected harms and non-monetary costs documented.
* **3.3** Application scope specified.
* **3.4** Operator proficiency requirements defined.
* **3.5** Human-oversight processes defined.

➡ **Theme:** capability ≠ acceptability.

---

## MAP 4 — Component-level risk mapping

* **4.1** Legal/technical risks of components and third-party assets mapped.
* **4.2** Internal controls for components documented.

➡ **Theme:** decompose the system to see risk.

---

## MAP 5 — Impact characterization

* **5.1** Likelihood and magnitude of impacts identified.
* **5.2** Continuous stakeholder engagement mechanisms exist.

➡ **Theme:** quantify harm before deployment.

---

# MEASURE — Risk analysis and validation

## MEASURE 1 — Metrics and methodologies

* **1.1** Metrics selected for highest-priority risks.
* **1.2** Metric effectiveness and controls regularly reassessed.
* **1.3** Independent/internal/external experts participate in assessment.

➡ **Theme:** measurement must be credible.

---

## MEASURE 2 — Trustworthiness evaluation

* **2.1** Test sets, metrics, and tools documented.
* **2.2** Human-subject evaluations meet protections/requirements.

➡ **Theme:** TEVV formalizes AI assurance.
