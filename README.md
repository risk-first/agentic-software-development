# Agentic Software Development Risk Framework

A risk framework for **agentic AI software development** — addressing the unique threats that emerge when humans employ AI systems to help write, modify, and deploy code.

## Why This Exists

Existing AI governance frameworks like **NIST AI RMF** and **ISO/IEC 42001** focus on:

- AI as a decision-making component
- Model lifecycle governance
- Organizational accountability

Conversely, this risk framework covers the exact use-case that AI is no longer just making decisions inside software — it is becoming the **primary producer and modifier** of software itself.   This shifts risk from *"bad AI decision"* to *"unsafe evolving codebase"* — a completely different class of risk that current frameworks don't address.

## Risk-First

This framework builds on [Risk-First Software Development](https://riskfirst.org) principles and can be navigated there as HTML (which provides a more joined up experience than just looking at these markdown files).

## What This Framework Covers

### Threat Categories

Risks unique to or amplified by agentic software development. 

### Control Families

Six control domains to address agentic SDLC risk.

## 



> **Manage downside before enabling capability.**

It is designed to be compatible with:
- CI/CD implementation patterns
- FINOS-style governance specifications
- Enterprise security frameworks

## Contributing

This is an emerging area with significant open problems:

- Provable correctness of agent-generated code
- Runtime monitoring of autonomous planning
- Standardized agent audit logs
- Cross-agent trust and identity

## License

This work is licensed under [Creative Commons Attribution 4.0 International (CC-BY 4.0)](LICENSE).
